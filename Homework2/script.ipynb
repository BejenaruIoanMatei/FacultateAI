{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Race  Nombre  Zone  Obs  Timide  Calme  Effrayé  Intelligent  Affectueux  \\\n",
      "0    12       3     2    1       1      1        1            1           1   \n",
      "1    12       1     2    2       1      1        3            3           5   \n",
      "2     4       4     2    2       4      4        3            5           5   \n",
      "3     4       1     1    2       3      2        2            4           4   \n",
      "4    12       2     1    2       1      4        1            4           4   \n",
      "\n",
      "   Amical  Solitaire  Impulsif  Prévisible  Distrait  Abondance  Pred  \n",
      "0       1          1         1           1         1          3     1  \n",
      "1       5          1         2           4         3          3     0  \n",
      "2       4          2         1           4         2          3     0  \n",
      "3       4          3         3           4         4          2     1  \n",
      "4       2          1         2           3         3          2     0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "file_path = '../Dataset/dataset_final_v1.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race\n",
      "4     1022\n",
      "6      483\n",
      "1      239\n",
      "10     217\n",
      "5      198\n",
      "12     192\n",
      "9      192\n",
      "2      166\n",
      "0      135\n",
      "7       80\n",
      "13      76\n",
      "8       58\n",
      "3       31\n",
      "14      28\n",
      "11      26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = df[\"Race\"]\n",
    "X = df.drop(columns=[\"Race\"]) \n",
    "\n",
    "y_encoded = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "print(y.value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bogdan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2458 - loss: 2.4621 - val_accuracy: 0.3340 - val_loss: 2.2140\n",
      "Epoch 2/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3253 - loss: 2.2415 - val_accuracy: 0.3340 - val_loss: 2.2302\n",
      "Epoch 3/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3251 - loss: 2.2045 - val_accuracy: 0.3300 - val_loss: 2.2053\n",
      "Epoch 4/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3334 - loss: 2.1880 - val_accuracy: 0.3340 - val_loss: 2.1901\n",
      "Epoch 5/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3306 - loss: 2.1606 - val_accuracy: 0.3320 - val_loss: 2.2026\n",
      "Epoch 6/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3185 - loss: 2.1998 - val_accuracy: 0.3300 - val_loss: 2.2183\n",
      "Epoch 7/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3134 - loss: 2.1948 - val_accuracy: 0.3300 - val_loss: 2.1921\n",
      "Epoch 8/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3024 - loss: 2.2072 - val_accuracy: 0.3300 - val_loss: 2.2086\n",
      "Epoch 9/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3178 - loss: 2.1633 - val_accuracy: 0.3320 - val_loss: 2.1789\n",
      "Epoch 10/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3225 - loss: 2.2080 - val_accuracy: 0.3300 - val_loss: 2.2124\n",
      "Epoch 11/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2965 - loss: 2.2337 - val_accuracy: 0.3300 - val_loss: 2.2086\n",
      "Epoch 12/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2937 - loss: 2.2415 - val_accuracy: 0.3320 - val_loss: 2.1987\n",
      "Epoch 13/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3131 - loss: 2.2214 - val_accuracy: 0.3300 - val_loss: 2.2210\n",
      "Epoch 14/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3233 - loss: 2.1818 - val_accuracy: 0.3300 - val_loss: 2.1988\n",
      "Epoch 15/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3182 - loss: 2.1849 - val_accuracy: 0.3300 - val_loss: 2.2157\n",
      "Epoch 16/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3187 - loss: 2.1727 - val_accuracy: 0.3300 - val_loss: 2.2235\n",
      "Epoch 17/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3344 - loss: 2.1656 - val_accuracy: 0.3260 - val_loss: 2.2126\n",
      "Epoch 18/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3115 - loss: 2.2243 - val_accuracy: 0.3300 - val_loss: 2.2053\n",
      "Epoch 19/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3236 - loss: 2.1873 - val_accuracy: 0.3320 - val_loss: 2.2192\n",
      "Epoch 20/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3209 - loss: 2.1812 - val_accuracy: 0.3320 - val_loss: 2.2080\n",
      "Epoch 21/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3422 - loss: 2.1877 - val_accuracy: 0.3300 - val_loss: 2.2071\n",
      "Epoch 22/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3086 - loss: 2.2205 - val_accuracy: 0.3320 - val_loss: 2.2078\n",
      "Epoch 23/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2975 - loss: 2.2181 - val_accuracy: 0.3300 - val_loss: 2.2016\n",
      "Epoch 24/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3416 - loss: 2.1556 - val_accuracy: 0.3340 - val_loss: 2.2041\n",
      "Epoch 25/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3300 - loss: 2.2017 - val_accuracy: 0.3300 - val_loss: 2.2233\n",
      "Epoch 26/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3210 - loss: 2.1979 - val_accuracy: 0.3360 - val_loss: 2.2203\n",
      "Epoch 27/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3211 - loss: 2.2036 - val_accuracy: 0.3320 - val_loss: 2.2251\n",
      "Epoch 28/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3136 - loss: 2.2188 - val_accuracy: 0.3340 - val_loss: 2.2243\n",
      "Epoch 29/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3130 - loss: 2.1805 - val_accuracy: 0.3360 - val_loss: 2.2234\n",
      "Epoch 30/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3226 - loss: 2.2080 - val_accuracy: 0.3320 - val_loss: 2.2288\n",
      "Epoch 31/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3196 - loss: 2.1823 - val_accuracy: 0.3340 - val_loss: 2.2228\n",
      "Epoch 32/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3244 - loss: 2.1772 - val_accuracy: 0.3340 - val_loss: 2.2202\n",
      "Epoch 33/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3372 - loss: 2.1596 - val_accuracy: 0.3360 - val_loss: 2.2082\n",
      "Epoch 34/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3051 - loss: 2.2049 - val_accuracy: 0.3280 - val_loss: 2.2191\n",
      "Epoch 35/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3431 - loss: 2.2071 - val_accuracy: 0.3320 - val_loss: 2.2208\n",
      "Epoch 36/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3418 - loss: 2.1594 - val_accuracy: 0.3360 - val_loss: 2.2073\n",
      "Epoch 37/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3195 - loss: 2.1773 - val_accuracy: 0.3320 - val_loss: 2.2076\n",
      "Epoch 38/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3131 - loss: 2.2280 - val_accuracy: 0.3320 - val_loss: 2.2188\n",
      "Epoch 39/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3262 - loss: 2.1646 - val_accuracy: 0.3280 - val_loss: 2.2076\n",
      "Epoch 40/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3272 - loss: 2.1743 - val_accuracy: 0.3300 - val_loss: 2.2106\n",
      "Epoch 41/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3459 - loss: 2.1237 - val_accuracy: 0.3320 - val_loss: 2.2129\n",
      "Epoch 42/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3489 - loss: 2.1436 - val_accuracy: 0.3300 - val_loss: 2.2040\n",
      "Epoch 43/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3152 - loss: 2.2140 - val_accuracy: 0.3340 - val_loss: 2.2080\n",
      "Epoch 44/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3068 - loss: 2.2066 - val_accuracy: 0.3280 - val_loss: 2.2055\n",
      "Epoch 45/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3213 - loss: 2.1743 - val_accuracy: 0.3380 - val_loss: 2.2031\n",
      "Epoch 46/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3135 - loss: 2.2226 - val_accuracy: 0.3300 - val_loss: 2.2222\n",
      "Epoch 47/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3119 - loss: 2.1771 - val_accuracy: 0.3340 - val_loss: 2.1965\n",
      "Epoch 48/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3285 - loss: 2.1758 - val_accuracy: 0.3340 - val_loss: 2.1950\n",
      "Epoch 49/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3004 - loss: 2.2062 - val_accuracy: 0.3300 - val_loss: 2.2124\n",
      "Epoch 50/50\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3360 - loss: 2.1507 - val_accuracy: 0.3320 - val_loss: 2.1999\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3186 - loss: 2.3272  \n",
      "Test Loss: 2.3270320892333984\n",
      "Test Accuracy: 33.23%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=10, validation_split=0.2)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
